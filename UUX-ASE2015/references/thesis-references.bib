Automatically generated by Mendeley Desktop 1.13.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Li2006,
author = {Li, Tao and Zhang, C and Zhu, S},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/Empirical Studies on Multi-label Classification.pdf:pdf},
journal = {IcTAI},
pages = {1--4},
title = {{Empirical Studies on Multi-label Classification.}},
url = {https://www.cs.rochester.edu/u/zhangchl/publications/ictai06.pdf},
year = {2006}
}
@article{Wu2010,
abstract = {The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.},
author = {Wu, Yingcai and Wei, Furu and Liu, Shixia and Au, Norman},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/FeedbackVisualisation/OpinionSeer Interactive Visualization of Hotel Customer Feedback.pdf:pdf},
journal = {Visualization and \ldots},
keywords = {opinion visualization,radial visualization,uncertainty visualization},
number = {6},
pages = {1109--1118},
title = {{OpinionSeer: interactive visualization of hotel customer feedback}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5613449},
volume = {16},
year = {2010}
}
@article{Wu2013,
abstract = {This paper proposes a novel approach based on review mining to analyze product usability. The massive online customer reviews on products is used as source data. Opinion mining technology is adopted to translate the unstructured reviews into structured feature-opinion pairs. Then, factor analysis technique is utilized to extract the feature-opinion pairs related to usability for product usability evaluation. Finally, a case study is presented to prove the effectiveness of the proposed approach. © 2013 IEEE.},
author = {Wu, Mingxing and Wang, Liya and Yi, Li},
file = {:Users/elsabakiu/Library/Application Support/Mendeley Desktop/Downloaded/Wu, Wang, Yi - 2013 - A novel approach based on review mining for product usability analysis.pdf:pdf},
isbn = {9781467350006},
journal = {Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
keywords = {factor analysis,product usability,review mining},
number = {71},
pages = {942--945},
title = {{A novel approach based on review mining for product usability analysis}},
year = {2013}
}
@misc{Edition2001,
author = {Edition, Third},
doi = {10.1002/1521-3773(20010316)40:6<9823::AID-ANIE9823>3.3.CO;2-C},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/eBooks/1. Data Mining - Practical Machine Learning Tools and Techniques.pdf:pdf},
isbn = {9780123748560},
issn = {14337851},
month = mar,
number = {6},
pages = {9823},
title = {{No Title}},
volume = {40},
year = {2001}
}
@article{Bermingham2009,
abstract = {Evaluation of sentiment analysis, like large-scale IR evalu ation, relies on the accuracy of human assessors to create judgments. Subjectivity in judgments is a problem for relevance assessment and even more so in the case of sentiment annotations. In this study we examine the degree to which assessors agree upon sentence-level sentiment annotation. We show that inter-assessor agreement is not contingent on document length or frequency of sentiment but correlates positively with automated opinion retrieval per- formance. We also examine the individual annotation categories to determine which categories pose most difficulty for annotators.},
author = {Bermingham, Adam and Smeaton, Alan F},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/A Study of Inter-Annotator Agreement for Opinion Retrieval.pdf:pdf},
isbn = {9781605584836},
journal = {Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval SIGIR 09},
pages = {784},
publisher = {ACM Press},
title = {{A study of inter-annotator agreement for opinion retrieval}},
url = {http://portal.acm.org/citation.cfm?doid=1571941.1572127},
year = {2009}
}
@article{From2010,
author = {From, Earning},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/Multilabel classification papers.pdf:pdf},
title = {{2 ND I NTERNATIONAL W ORKSHOP O N L EARNING FROM M ULTI -L ABEL D ATA Working Notes Haifa , Israel}},
year = {2010}
}
@article{Mendes2013,
author = {Mendes, MS and Furtado, ES},
file = {:Users/elsabakiu/Library/Application Support/Mendeley Desktop/Downloaded/Mendes, Furtado - 2013 - A Study about the usability evaluation of Social Systems from messages in Natural Language.pdf:pdf},
journal = {Human Computer \ldots},
keywords = {guage,human computer interaction,natural processing lan-,social systems,usability},
pages = {59--62},
title = {{A Study about the usability evaluation of Social Systems from messages in Natural Language}},
url = {http://link.springer.com/chapter/10.1007/978-3-319-03068-5\_12},
year = {2013}
}
@article{Landau1937a,
author = {Landau, LD},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/walmart.pdf:pdf},
journal = {Zhurnal Eksperimental'noi i Teoreticheskoi Fiziki},
keywords = {corporate opinion,corpus annotation,management,reliability test,reputation,sentiment analysis},
title = {{No Title}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:No+Title\#0},
year = {1937}
}
@article{Wang2012,
abstract = {Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the oppo- site result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on senti- ment analysis datasets, sometimes providing a new state-of-the-art performance level.},
author = {Wang, Sida and Manning, Christopher D Cd},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/Baselines and Bigrams Simple, Good Sentiment and Topic Classification.pdf:pdf},
journal = {ACL 12 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2},
keywords = {IMDB-DataSet,Movie-DataSet,NB,NBSVM,SVM},
number = {1},
pages = {90--94},
title = {{Baselines and bigrams: Simple, good sentiment and topic classification}},
volume = {94305},
year = {2012}
}
@article{Sechidis2011,
author = {Sechidis, Konstantinos and Tsoumakas, Grigorios and Vlahavas, Ioannis},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/On the Stratification of Multi-Label Data.pdf:pdf},
journal = {Machine Learning and Knowledge \ldots},
title = {{On the stratification of multi-label data}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-23808-6\_10},
year = {2011}
}
@article{EckleKohler2013,
author = {Eckle‐Kohler, J},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/Automatically Assigning Research Methods to Journal  Articles in the Domain of Social Sciences .pdf:pdf},
journal = {Proceedings of the \ldots},
keywords = {2010,botte 2013,e,g,is investigated,methodologies used,of,or if the use,research methods over time,sondergeld,wallace et al},
pages = {1--8},
title = {{Automatically assigning research methods to journal articles in the domain of social sciences}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/meet.14505001049/full},
year = {2013}
}
@incollection{Barbier2011,
abstract = {The rise of online social media is providing a wealth of social network$\backslash$ndata. Data mining techniques provide researchers and practitioners$\backslash$nthe tools needed to analyze large, complex, and frequently changing$\backslash$nsocial media data. This chapter introduces the basics of data mining,$\backslash$nreviews social media, discusses how to mine social media data, and$\backslash$nhighlights some illustrative examples with an emphasis on social$\backslash$nnetworking sites and blogs.},
author = {Barbier, Geoffrey and Liu, Huan},
booktitle = {Social Network Data Analytics},
doi = {10.1007/978-1-4419-8462-3\_12},
isbn = {978-1-4419-8461-6},
keywords = {blogosphere,blogs,data mining,data representation,event maps,social computing,social media,social networking sites,social networks},
pages = {327--352},
title = {{Data Mining in Social Media}},
url = {http://dx.doi.org/10.1007/978-1-4419-8462-3\_12},
year = {2011}
}
@article{Jia2009,
abstract = {Abstract We investigate the problem of determining the polarity of sentiments when one or more occurrences of a negation term such as" not" appear in a sentence. The concept of the scope of a negation term is introduced. By using a parse tree and typed dependencies ...},
author = {Jia, Lifeng and Yu, Clement and Meng, Weiyi},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/The Effect of Negation on Sentiment Analysis and  Retrieval Effectiveness .pdf:pdf},
isbn = {9781605585123},
journal = {Proceeding of the 18th ACM conference},
keywords = {candidate scope of negation,opinion retrieval,retrieval effectiveness,scope of negation,sentiment analysis},
number = {c},
pages = {1827--1830},
publisher = {Acm},
title = {{The effect of negation on sentiment analysis and retrieval effectiveness}},
url = {http://portal.acm.org/citation.cfm?doid=1645953.1646241},
year = {2009}
}
@article{Bornebusch2014,
author = {Bornebusch, Fritjof and Cancino, Glaucia and Diepenbeck, Melanie},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/Aspect Based Sentiment Analysis using Sentiment Trees and Dictionaries.pdf:pdf},
journal = {SemEval 2014},
number = {SemEval},
pages = {351--355},
title = {{iTac: Aspect Based Sentiment Analysis using Sentiment Trees and Dictionaries}},
url = {http://www.aclweb.org/anthology/S/S14/S14-2.pdf\#page=371},
year = {2014}
}
@article{Modi2012,
author = {Modi, Hiteshri and Panchal, M},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/Comparison of Different Problem  Transformation Methods for Multi-Label Classification.pdf:pdf},
journal = {Int. J. Comput. Appl},
keywords = {binary relevance,label power-set,label ranking,meka,multi-label ranking,pruned set},
number = {15},
pages = {10--15},
title = {{Experimental comparison of different problem transformation methods for multi-label classification using MEKA}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Experimental+Comparison+of+Different+Problem+Transformation+Methods+for+Multi-Label+Classification+using+MEKA\#0},
volume = {59},
year = {2012}
}
@article{Hovy2006,
author = {Hovy, Eduard and Marcus, Mitchell and Palmer, Martha},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/OntoNotes- The 90\% Solution.pdf:pdf},
journal = {Proceedings of the \ldots},
number = {June},
pages = {57--60},
title = {{OntoNotes: the 90\% solution}},
url = {http://dl.acm.org/citation.cfm?id=1614064},
year = {2006}
}
@book{Liu,
author = {Liu, Bing},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/eBooks/2. DTM-SentimentAnalysisAndOpinionMining-BingLiu.pdf:pdf},
isbn = {9781608458844},
title = {{Sentiment Sentiment Analysis Analysis and and Opinion Opinion Mining Mining}}
}
@article{Hedegaard2013,
abstract = {nternet review sites allow consumers to write detailed reviews of products potentially containing information related to user experience (UX) and usability. Using 5198 sentences from 3492 online reviews of software and video games, we investigate the content of online reviews with the aims of (i) charting the distribution of information in reviews among different dimensions of usability and UX, and (ii) extracting an associated vocabulary for each dimension using techniques from natural language processing and machine learning. We (a) find that 13\%-49\% of sentences in our online reviews pool contain usability or UX information; (b) chart the distribution of four sets of dimensions of usability and UX across reviews from two product categories; (c) extract a catalogue of important word stems for a number of dimensions. Our results suggest that a greater understanding of users' preoccupation with different dimensions of usability and UX may be inferred from the large volume of self-reported experiences online, and that research focused on identifying pertinent dimensions of usability and UX may benefit further from empirical studies of user-generated experience reports.},
author = {Hedegaard, Steffen and Simonsen, Jakob Grue},
file = {:Users/elsabakiu/Library/Application Support/Mendeley Desktop/Downloaded/Hedegaard, Simonsen - 2013 - Extracting usability and user experience information from online user reviews.pdf:pdf},
isbn = {9781450318990},
journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI '13},
keywords = {User experience,end user reviews,machine learning,natural language processing,usability},
pages = {2089},
title = {{Extracting usability and user experience information from online user reviews}},
url = {http://dl.acm.org/citation.cfm?doid=2470654.2481286},
year = {2013}
}
@article{Sim2005,
abstract = {PURPOSE: This article examines and illustrates the use and interpretation of the kappa statistic in musculoskeletal research. SUMMARY OF KEY POINTS: The reliability of clinicians' ratings is an important consideration in areas such as diagnosis and the interpretation of examination findings. Often, these ratings lie on a nominal or an ordinal scale. For such data, the kappa coefficient is an appropriate measure of reliability. Kappa is defined, in both weighted and unweighted forms, and its use is illustrated with examples from musculoskeletal research. Factors that can influence the magnitude of kappa (prevalence, bias, and non-independent ratings) are discussed, and ways of evaluating the magnitude of an obtained kappa are considered. The issue of statistical testing of kappa is considered, including the use of confidence intervals, and appropriate sample sizes for reliability studies using kappa are tabulated. CONCLUSIONS: The article concludes with recommendations for the use and interpretation of kappa.},
author = {Sim, J and Wright, C C},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/The Kappa Statistic in Reliability Studies.pdf:pdf},
journal = {Phys Ther},
keywords = {*Data Interpretation,*Reproducibility of Results,Humans,Models,Musculoskeletal Diseases/*diagnosis/epidemiology/p,Observer Variation,Physical Therapy (Specialty)/*standards,Prevalence,RF  - 60,Research/methods,Sample Size,Statistical},
number = {3},
pages = {257--268},
title = {{The kappa statistic in reliability studies: use, interpretation, and sample size requirements}},
volume = {85},
year = {2005}
}
@article{Maalej2013,
abstract = {Reading reference documentation is an important part of programming with APIs. Reference documentation complements the API by providing information not obvious from the API syntax. To improve the quality of reference documentation and the efﬁciency with which the relevant information it contains can be accessed, we must ﬁrst understand its content. We report on a study of the nature and organization of knowledge contained in the reference documentation of the hundreds of APIs provided as part of two major technology platforms: Java SDK 6 and .NET 4.0. Our study involved the development of a taxonomy of knowledge types based on grounded methods and independent empirical validation. Seventeen trained coders used the taxonomy to rate a total of 5574 randomly-sampled documentation units to assess the knowledge they contain. Our results provide a comprehensive perspective on the patterns of knowledge in API documentation: observations about the types of knowledge it contains, and how this knowledge is distributed throughout the documentation. The taxonomy and patterns of knowledge we present in this paper can be used to help practitioners evaluate the content of their API documentation, better organize their documentation, and limit the amount of low-value content. They also provides a vocabulary that can help structure and facilitate discussions about the content of APIs.},
author = {Maalej, Walid and Robillard, Martin P.},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/Disagreement handling - Scaling Requirements Extraction to the Crowd.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {.NET,API documentation,Java,content analysis,data mining,empirical study,grounded method,pattern mining,software documentation},
number = {9},
pages = {1264--1282},
title = {{Patterns of knowledge in API reference documentation}},
volume = {39},
year = {2013}
}
@misc{Graffox2009,
abstract = {Citiation standards are provided for: Books, Handbooks, Reports, Conference Technical Articles, Online Sources, Patents, Standards, Theses, Unpublished, Periodicals and References},
author = {Graffox, D.},
booktitle = {Retrieved Mar},
title = {{IEEE Citation Reference}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:IEEE+Citation+Reference\#5},
year = {2009}
}
@article{Guzman2014,
author = {Guzman, Emitza and Maalej, W},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/FeatureSentiments.pdf:pdf},
journal = {Requirements Engineering Conference \ldots},
title = {{How do users like this feature? a fine grained sentiment analysis of app reviews}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6912257},
year = {2014}
}
@book{Designer,
author = {Designer, Every and To, Needs and About, Know},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/eBooks/1. 100 Things Every Designer Needs To Know About People (2011).pdf:pdf},
isbn = {9780321767530},
title = {{100 THINGS}}
}
@article{Socher2013,
abstract = {Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80\% up to 85.4\%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7\%, an improvement of 9.7\% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.},
author = {Socher, Richard and Perelygin, Alex and Wu, Jy},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank.pdf:pdf},
journal = {Proceedings of the \ldots},
pages = {1631--1642},
title = {{Recursive deep models for semantic compositionality over a sentiment treebank}},
url = {http://nlp.stanford.edu/~socherr/EMNLP2013\_RNTN.pdf$\backslash$nhttp://www.aclweb.org/anthology/D13-1170$\backslash$nhttp://aclweb.org/supplementals/D/D13/D13-1170.Attachment.pdf$\backslash$nhttp://oldsite.aclweb.org/anthology-new/D/D13/D13-1170.pdf http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Recursive+deep+models+for+semantic+compositionality+over+a+sentiment+treebank\#0},
year = {2013}
}
@article{Rosa2013,
author = {Rosa, Renata Lopes},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/Facebook and Twitter Analysis Tool to Discover Consumers Sentiment.pdf:pdf},
isbn = {9781612082790},
journal = {AICT 2013, The Ninth \ldots},
keywords = {but the study analyzes,consumer sentiment,facebook,learning,machine,only one specific micro-blog,sales and features of,smartphones or,social networks to analyze,social web analysis tool,support vector machines,twitter,using},
number = {c},
pages = {61--66},
title = {{SentiMeter-Br: Facebook and Twitter Analysis Tool to Discover Consumers' Sentiment}},
url = {http://www.thinkmind.org/index.php?view=article\&articleid=aict\_2013\_3\_30\_10191},
year = {2013}
}
@article{Chen2014,
author = {Chen, Jilin and Hsieh, Gary and Mahmud, JU and Nichols, Jeffrey},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/User Personality/Understanding Individuals’ Personal Values  from Social Media Word Use.pdf:pdf},
isbn = {9781450325400},
journal = {Proceedings of the 17th ACM \ldots},
pages = {405--414},
title = {{Understanding individuals' personal values from social media word use}},
url = {http://dl.acm.org/citation.cfm?id=2531608},
year = {2014}
}
@article{Hogenboom2011,
abstract = {A key element for decision makers to track is their stakeholders' sentiment. Recent developments show a tendency of including various aspects other than word frequencies in automated sentiment analysis approaches. One of these aspects is negation, which can be accounted for in various ways. We compare several approaches to accounting for negation in sentiment analysis, differing in their methods of determining the scope of influence of a negation keyword. On a set of English movie review sentences, the best approach is to consider two words, following a negation keyword, to be negated by that keyword. This method yields a significant increase in overall sentiment classification accuracy and macro-level F<inf>1</inf> of 5.5\% and 6.2\%, respectively, compared to not accounting for negation. Additionally optimizing sentiment modification of negated words to a value of \&\#x2212;1.27 rather than \&\#x2212;1 yields a significant 7.1\% increase in accuracy and a significant 8.0\% increase in macro-level F<inf>1</inf>.},
author = {Hogenboom, Alexander and {Van Iterson}, Paul and Heerschop, Bas and Frasincar, Flavius and Kaymak, Uzay},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/Determining Negation Scope and Strength in Sentiment Analysis.pdf:pdf},
journal = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
keywords = {Sentiment analysis,negation scope,negation strength},
pages = {2589--2594},
title = {{Determining negation scope and strength in sentiment analysis}},
year = {2011}
}
@article{Madjarov2012,
abstract = {Multi-label learning has received significant attention in the research community over the past few years: this has resulted in the development of a variety of multi-label learning methods. In this paper, we present an extensive experimental comparison of 12 multi-label learning methods using 16 evaluation measures over 11 benchmark datasets. We selected the competing methods based on their previous usage by the community, the representation of different groups of methods and the variety of basic underlying machine learning methods. Similarly, we selected the evaluation measures to be able to assess the behavior of the methods from a variety of view-points. In order to make conclusions independent from the application domain, we use 11 datasets from different domains. Furthermore, we compare the methods by their efficiency in terms of time needed to learn a classifier and time needed to produce a prediction for an unseen example. We analyze the results from the experiments using Friedman and Nemenyi tests for assessing the statistical significance of differences in performance. The results of the analysis show that for multi-label classification the best performing methods overall are random forests of predictive clustering trees (RF-PCT) and hierarchy of multi-label classifiers (HOMER), followed by binary relevance (BR) and classifier chains (CC). Furthermore, RF-PCT exhibited the best performance according to all measures for multi-label ranking. The recommendation from this study is that when new methods for multi-label learning are proposed, they should be compared to RF-PCT and HOMER using multiple evaluation measures. © 2012 Elsevier Ltd. All rights reserved.},
author = {Madjarov, Gjorgji and Kocev, Dragi and Gjorgjevikj, Dejan and D\v{z}eroski, Sa\v{s}o},
doi = {10.1016/j.patcog.2012.03.004},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/An extensive experimental comparison of methods for multi-label learning.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Comparison of multi-label learning methods,Multi-label classification,Multi-label ranking},
month = sep,
number = {9},
pages = {3084--3104},
title = {{An extensive experimental comparison of methods for multi-label learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320312001203},
volume = {45},
year = {2012}
}
@article{Spolaor2013,
author = {Spola\^{o}r, N and Tsoumakas, G},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/Evaluating Feature Selection Methods for Multi-Label Text Classification .pdf:pdf},
journal = {Proceedings of the first workshop on bio \ldots},
keywords = {bi-normal separation,binary relevance,chi-squared,problem transformation,rand-robin,round-robin},
pages = {1--12},
title = {{Evaluating Feature Selection Methods for Multi-Label Text Classification}},
url = {http://talos.csd.auth.gr/tsoumakas/publications/C43.pdf},
year = {2013}
}
@article{Guzman,
author = {Guzman, Emitza and Bhuvanagiri, Padma and Bruegge, Bernd},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/FeedbackVisualisation/FeedbackVis.pdf:pdf},
journal = {conferences.computer.org},
pages = {3--7},
title = {{FAVe: Visualizing User Feedback for Software Evolution}},
url = {http://conferences.computer.org/vissoft/2014/papers/6150a167.pdf}
}
@article{El-Halees2014,
abstract = {Usability is critical for any system, but in software it is one of the most important features. In fact, one of the main reasons for software failure is the system lacking to achieve users specified goals and satisfaction. For this reason, usability evaluation is becoming an important part of software development. Software usability evaluation can be costly in terms of time and human. Therefore, automation is promising way to augment existing approaches especially if the evaluation is subjective where the usability concentrated about user's "opinion". This paper proposes to use opinion mining as an automatic technique to evaluate subjective usability. Opinion mining is a research subtopic of data mining aiming to automatically obtain useful opinioned knowledge in subjective texts. We propose a novel model to extract knowledge from opinions to improve subjective software usability. This is the first time opinion mining used in software usability. To evaluate our proposed model, a set of experiments was designed and conducted and we got an average accuracy of 85.41\%. Also, we propose to use graphics to visualize user's opinion in software and to compare the usability of two software. © 2014 ACADEMY PUBLISHER.},
author = {El-Halees, Alaa Mustafa},
doi = {10.4304/jsw.9.2.343-349},
file = {:Users/elsabakiu/Library/Application Support/Mendeley Desktop/Downloaded/El-Halees - 2014 - Software Usability Evaluation Using Opinion Mining.pdf:pdf},
issn = {1796-217X},
journal = {Journal of Software},
keywords = {Automatic evaluation,Opinion mining,Software usability,Usability evaluation,Usability testing},
month = feb,
number = {2},
pages = {343--349},
title = {{Software Usability Evaluation Using Opinion Mining}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84894430241\&partnerID=tZOtx3y1},
volume = {9},
year = {2014}
}
@article{Bazelli2013,
abstract = {In the last decade, developers have been increasingly sharing their questions with each other through Question and Answer (Q\&A) websites. As a result, these websites have become valuable knowledge repositories, covering a wealth of topics related to particular programming languages. This knowledge is even more useful as the developer community evaluates both questions and answers through a voting mechanism. As votes accumulate, the developer community recognizes reputed members and further trusts their answers. An interesting question that arises from this process is to recognize the elements that contribute to a developer’s reputation. In this paper, we analyze the community’s questions and answers to determine the developers’ personality traits, using the Linguistic Inquiry and Word Count (LIWC). We answer several questions related to the personalities of the Q\&A authors. Our results reveal that 2 out of the top 5 reputed authors share similar personality types. Moreover, posts tagged as “Android” and “C\#” are similar in terms of extroversion and openness whereas “JavaScript” posts measure less extroversion. Finally, readability measures indicate that up-voted questions are generally more readable than down-voted questions.},
author = {Bazelli, Blerina and Hindle, Abram and Stroulia, Eleni},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/User Personality/bazelli-personality-draft.pdf:pdf},
journal = {IEEE International Conference on Software Maintenance, ICSM},
pages = {460--463},
title = {{On the personality traits of StackOverflow users}},
year = {2013}
}
@article{Chekina2011,
abstract = {Although various algorithms for multi-label classification have been developed in recent years, there is little, if any, information as to when each method is beneficial. The main goal of this paper is to compare the classification performance of several multi-label algorithms and to develop a set of rules or tools that will help in selecting the optimal algorithm according to a specific dataset and target evaluation measure. We utilize a meta-learning approach allowing fast automatic selection of the most appropriate algorithm for an unseen dataset based on its descriptive characteristics. We also define a list of characteristics specific for multi-label datasets. The experimental results indicate the applicability and usefulness of the meta-learning approach.},
author = {Chekina, Lena and Rokach, Lior and Shapira, Bracha},
doi = {10.1109/ICDMW.2011.118},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Multilabel Classification/Meta-Learning for Selecting a Multi-Label Classification Algorithm .pdf:pdf},
isbn = {978-1-4673-0005-6},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Dataset characteristics,Evaluation measures,Meta-learning,Multi-label classification},
month = dec,
pages = {220--227},
publisher = {Ieee},
title = {{Meta-learning for selecting a multi-label classification algorithm}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6137383},
year = {2011}
}
@article{Pang2002,
author = {Pang, Bo and Lee, Lillian and Vaithyanathan, S},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/Papers/Sentiment Analysis/Sentiment Classification - Machine Learning.pdf:pdf},
journal = {\ldots of the ACL-02 conference on \ldots},
title = {{Thumbs up?: sentiment classification using machine learning techniques}},
url = {http://dl.acm.org/citation.cfm?id=1118704},
year = {2002}
}
@article{Landau1937,
author = {Landau, LD},
file = {:Users/elsabakiu/Dropbox/Master TUM/Semester 4/Master Thesis/eBooks/2. NaturalLanguageProcessingWithPython.pdf:pdf},
isbn = {9780596516499},
journal = {Zhurnal Eksperimental'noi i Teoreticheskoi Fiziki},
title = {{No Title}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:No+Title\#0},
year = {1937}
}
